import os
import hashlib
import datetime
import subprocess
import shutil
from pydantic import BaseModel
from pathlib import Path
from typing import Optional
from root_anchor import ROOT_DIR
from utils.git_helper import get_github_permalink


def copy_archives(dest_dir: Path):
    root_archives = Path(ROOT_DIR) / "archives"
    archive_dirs = [d for d in root_archives.iterdir() if d.is_dir()]

    packaged_list_path = dest_dir / "copied_list.txt"
    if packaged_list_path.exists():
        with packaged_list_path.open("r", encoding="utf-8") as f:
            already_packaged = set(line.strip() for line in f if line.strip())
    else:
        already_packaged = set()


    to_copy: list[Path] = [a for a in archive_dirs if a.name not in already_packaged]
    current_batch: list[Path] = []
    current_batch_size = 0
    for i in range(len(to_copy)):
        a = to_copy[i]
        print(f"processing {a.name}")


def generate_file_sha256(file_path: Path) -> Optional[str]:
    if not file_path.exists() or not file_path.is_file():
        return None

    sha256_hash = hashlib.sha256()
    with file_path.open("rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()


class CheckSumGenerationResult(BaseModel):
    digest_path: Optional[Path] = None
    checksum_dict: Optional[dict[str, str]] = None
    error: Optional[str] = None


def generate_archive_checksum_digest(archive_dir: Path) -> CheckSumGenerationResult:
    # recursively iterate over all the files in the archive_dir, for each one generate a sha256, and store it in a list of tuples (relative_path, sha256)
    if not archive_dir.exists() or not archive_dir.is_dir():
        return CheckSumGenerationResult(error=f"Archive directory {archive_dir} does not exist or is not a directory.")
    file_hashes = []
    checksum_dict = dict()
    for root, _, files in os.walk(archive_dir):
        for file in files:
            file_path = Path(root) / file
            relative_path = file_path.relative_to(archive_dir)
            file_sha256 = generate_file_sha256(file_path)
            if file_sha256 is not None:
                file_hashes.append((str(relative_path), file_sha256))
                checksum_dict[str(relative_path)] = file_sha256
    # sort the list of tuples by relative_path
    file_hashes.sort(key=lambda x: x[0])
    # concatenate the strings into a newline delimited string
    concatenated_string = '\n'.join([f"{h[1]} *{h[0]}" for h in file_hashes])
    preamble = f"# Archive checksum generated for archive '{archive_dir.name}'\n# Format: <sha256> *<relative_path>\n"
    preamble += f"# Total files: {len(file_hashes)}\n"
    timestamp = datetime.datetime.now(datetime.UTC).isoformat()
    preamble += f'# Timestamp: {timestamp}Z\n'
    preamble += f'# Generated Using {get_github_permalink()}/data_transfers/safe_copy.py\n'
    preamble += f'# DO NOT EDIT THIS FILE MANUALLY\n\n'
    digest = preamble + concatenated_string
    # store the digest in a checksum.txt file in the archive_dir
    checksum_path = archive_dir / f"checksum_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with checksum_path.open("w", encoding="utf-8") as f:
        f.write(digest)
        print(f"Written checksum file to {checksum_path}")
    return CheckSumGenerationResult(digest_path=checksum_path, checksum_dict=checksum_dict)

def safe_copy_archive(src_path: Path, dest_dir: Path) -> bool:
    # generate checksum for src_dir
    checksum = generate_archive_checksum_digest(src_path)
    if checksum.error is not None:
        print(f"Failed to generate checksum for source directory {src_path.name}")
        print(checksum.error)
        return False
    checksum_dict = checksum.checksum_dict
    max_retries = 5
    files_to_copy = list(checksum_dict.keys())
    successfully_copied = set()
    for attempt in range(max_retries):
        if len(successfully_copied) == len(files_to_copy):
            print(f"All files copied successfully after {attempt} attempts.")
            return True
        for relative_path in files_to_copy:
            if relative_path in successfully_copied:
                continue
            src_file_path = src_path / relative_path
            dest_file_path = dest_dir / src_path.name / relative_path
            dest_file_path.parent.mkdir(parents=True, exist_ok=True)
            try:
                if not dest_file_path.exists():
                    if os.name == "nt":
                        src_parent = str(src_file_path.parent)
                        dest_parent = str(dest_file_path.parent)
                        cmd = [
                            "robocopy",
                            src_parent,
                            dest_parent,
                            src_file_path.name,
                            "/COPY:DAT",
                            "/DCOPY:T",
                            "/NFL",
                            "/NDL",
                            "/NJH",
                            "/NJS",
                        ]
                        res = subprocess.run(cmd, capture_output=True)
                        print("robocopy stdout:", res.stdout)
                        print("robocopy stderr:", res.stderr)
                        if res.returncode >= 8:
                            raise Exception(f"robocopy failed with returncode {res.returncode}")
                    else:
                        shutil.copy2(src_file_path, dest_file_path)
                    with src_file_path.open("rb") as src_f, dest_file_path.open("wb") as dest_f:
                        dest_f.write(src_f.read())
                # verify checksum
                dest_file_sha256 = generate_file_sha256(dest_file_path)
                if dest_file_sha256 == checksum_dict[relative_path]:
                    successfully_copied.add(relative_path)
                else:
                    print(f"Checksum mismatch for {relative_path}, will retry.")
                    # cleanup failed copy
                    if dest_file_path.exists():
                        dest_file_path.unlink()
            except Exception as e:
                print(f"Error copying {relative_path}: {e}")
    # transfer the checksum digest file itself
    checksum_digest = checksum.digest_path
    if checksum_digest is not None:
        dest_checksum_path = dest_dir / src_path.name / checksum_digest.name
        shutil.copy2(checksum_digest, dest_checksum_path)
        print(f"Copied checksum digest to {dest_checksum_path}")
    if len(successfully_copied) != len(files_to_copy):
        print(f"Failed to copy all files after {max_retries} attempts.")
        return False
    return True

if __name__ == "__main__":
    archive_location = Path(input("Input path to archive directory: ").strip().strip('"').strip("'"))
    dest_directory = Path(input("Input path to destination directory: ").strip().strip('"').strip("'"))
    safe_copy_archive(archive_location, dest_directory)
